{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyozktSuJlvQ",
    "outputId": "b679cf1e-d952-4a15-9c72-9049c8ea048b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
      "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.5.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.6)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.10.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (0.11.8)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.10.10)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.16.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.17.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, TQDMProgressBar\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HTPxqfZFJlvS"
   },
   "outputs": [],
   "source": [
    "exp_name = '000_NN_NoImage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HM_ew0d1JlvS"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/Users/gouyashuto/localrepository/atmacup18/input')\n",
    "OUTPUT_DIR = Path('/Users/gouyashuto/localrepository/atmacup18/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9zWnSifJlvT",
    "outputId": "d4104dbd-0a1d-4425-d50f-203d52f0cf7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43371, 30)\n",
      "(1727, 12)\n"
     ]
    }
   ],
   "source": [
    "train_df = pl.read_csv(DATA_PATH / 'train_features.csv')\n",
    "test_df = pl.read_csv(DATA_PATH / 'test_features.csv')\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KTmucj6lJlvU"
   },
   "outputs": [],
   "source": [
    "CAT_COLS = ['gearShifter', 'scene']\n",
    "\n",
    "TARGET_COLS = [\n",
    "    'x_0', 'y_0', 'z_0',\n",
    "    'x_1', 'y_1', 'z_1',\n",
    "    'x_2', 'y_2', 'z_2',\n",
    "    'x_3', 'y_3', 'z_3',\n",
    "    'x_4', 'y_4', 'z_4',\n",
    "    'x_5', 'y_5', 'z_5'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pPiQOa8QJlvU"
   },
   "outputs": [],
   "source": [
    "def get_agg_exprs(agg_cols) -> list[pl.Expr]:\n",
    "    # 同一シーンから特徴量作成\n",
    "    exprs = []\n",
    "    exprs += [pl.col(agg_col).shift(-1).over(\"scene\").alias(f\"{agg_col}_shift-1\") for agg_col in agg_cols] # 1ステップ前の時間の値\n",
    "    exprs += [pl.col(agg_col).shift(1).over(\"scene\").alias(f\"{agg_col}_shift1\") for agg_col in agg_cols] # 1ステップ後の時間の値\n",
    "    exprs += [pl.col(agg_col).diff(-1).over(\"scene\").alias(f\"{agg_col}_diff-1\") for agg_col in agg_cols] # 1ステップ前の時間の値との差分\n",
    "    exprs += [pl.col(agg_col).diff(1).over(\"scene\").alias(f\"{agg_col}_diff1\") for agg_col in agg_cols] # 1ステップ後の時間の値との差分\n",
    "    exprs += [pl.col(agg_col).mean().over(\"scene\").alias(f\"{agg_col}_mean\") for agg_col in agg_cols] # 同一シーンの平均値\n",
    "    exprs += [pl.col(agg_col).std().over(\"scene\").alias(f\"{agg_col}_std\") for agg_col in agg_cols] # 同一シーンの標準偏差\n",
    "    exprs += [pl.col(agg_col).max().over(\"scene\").alias(f\"{agg_col}_max\") for agg_col in agg_cols] # 同一シーンの最大値\n",
    "    exprs += [pl.col(agg_col).min().over(\"scene\").alias(f\"{agg_col}_min\") for agg_col in agg_cols] # 同一シーンの最小値\n",
    "    return exprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "20pBJ1c9JlvW"
   },
   "outputs": [],
   "source": [
    "def preprocess(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    agg_cols = ['vEgo', 'aEgo', 'steeringAngleDeg', 'steeringTorque', 'gas'] # 同一シーンから集計する値のカラム名\n",
    "    df = (\n",
    "        df\n",
    "        .with_columns(\n",
    "            scene = pl.col('ID').str.split('_').list[0],\n",
    "            decisecond = pl.col('ID').str.split('_').list[1].cast(pl.Int32),\n",
    "        )\n",
    "        .sort(['scene', 'decisecond'])\n",
    "        .with_columns(get_agg_exprs(agg_cols))\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Hi7fX5aJlvX"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qMhGPELeJlva"
   },
   "outputs": [],
   "source": [
    "class MLPDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        features: pd.DataFrame,\n",
    "        targets: pd.DataFrame,\n",
    "    ):\n",
    "        self.features = features.values\n",
    "        self.targets = targets.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.features[index]\n",
    "        targets = self.targets[index]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(features, dtype=torch.float),\n",
    "            torch.tensor(targets, dtype=torch.float),\n",
    "        )\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        features: pd.DataFrame,\n",
    "    ):\n",
    "        self.features = features.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.features[index]\n",
    "\n",
    "        return torch.tensor(features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUCiZkMlJlvb"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOXuMwyNJlvb",
    "outputId": "d8b17fd6-9521-4e44-c61c-04ff2f2a2331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 18])\n",
      "tensor([[ 0.0189,  0.0607,  0.0861, -0.1658,  0.0208,  0.0201,  0.1802, -0.1413,\n",
      "         -0.0683,  0.0515,  0.0894,  0.0587,  0.2160,  0.0752, -0.1135, -0.0469,\n",
      "         -0.1377,  0.0232],\n",
      "        [-0.0541, -0.0602,  0.0029, -0.1399, -0.0520, -0.1057,  0.1586, -0.2311,\n",
      "         -0.2254,  0.1875,  0.0515,  0.0254,  0.2069, -0.1377,  0.3052, -0.0423,\n",
      "          0.0830, -0.1090]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# define a class for the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "input_dim = 100\n",
    "output_dim = 18\n",
    "model = MLP(input_dim, output_dim)\n",
    "input = torch.randn(2, input_dim)\n",
    "output = model(input)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2n1zmweMJlvc"
   },
   "outputs": [],
   "source": [
    "class MLPModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self, config, input_dim: int, output_dim: int, num_warmup_steps: int | None = None, num_training_steps: int | None = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.backbone = MLP(input_dim, output_dim)\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        self.num_training_steps = num_training_steps\n",
    "        self.loss_fn = nn.L1Loss()\n",
    "\n",
    "        # == record ==\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, target = batch\n",
    "\n",
    "        x = x.to(CONFIG['device'])\n",
    "        target = target.to(CONFIG['device'])\n",
    "\n",
    "        y_pred = self(x)\n",
    "\n",
    "        loss = self.loss_fn(y_pred, target.float())\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, target = batch\n",
    "        x = x.to(CONFIG['device'])\n",
    "        target = target.to(CONFIG['device'])\n",
    "\n",
    "        # == pred ==\n",
    "        with torch.no_grad():\n",
    "            y_pred = self(x)\n",
    "\n",
    "        self.validation_step_outputs.append({\"preds\": y_pred, \"targets\": target})\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "\n",
    "        # = merge batch data =\n",
    "        outputs = self.validation_step_outputs\n",
    "\n",
    "        output_val = torch.cat([x['preds'] for x in outputs], dim=0).cpu().detach()\n",
    "        target_val = torch.cat([x['targets'] for x in outputs], dim=0).cpu().detach()\n",
    "\n",
    "        # = compute validation loss =\n",
    "        loss = self.loss_fn(output_val.squeeze(), target_val.float())\n",
    "\n",
    "        self.log(\"valid_loss\", loss, True)\n",
    "\n",
    "        # clear validation outputs\n",
    "        self.validation_step_outputs = list()\n",
    "\n",
    "        return {'valid_loss': loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # == define optimizer ==\n",
    "        model_optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.config[\"learning_rate\"],\n",
    "            weight_decay=self.config[\"weight_decay\"],\n",
    "        )\n",
    "\n",
    "        # == define learning rate scheduler ==\n",
    "        lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "            model_optimizer,\n",
    "            num_warmup_steps=self.num_warmup_steps,\n",
    "            num_training_steps=self.num_training_steps,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": model_optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": lr_scheduler,\n",
    "                \"interval\": \"epoch\",\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vi8TuELJlvc"
   },
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KiOdx-wYJlvc"
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"output_dir\": OUTPUT_DIR / exp_name,\n",
    "    \"train_batch_size\": 16,  # 32\n",
    "    \"valid_batch_size\": 64,\n",
    "    \"learning_rate\": 5e-2,\n",
    "    # \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 500,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"patience\": 10,\n",
    "    \"n_accumulate\": 1,\n",
    "    'folds': 5,\n",
    "    'n_workers': 4,\n",
    "    'debug': True,\n",
    "    'mixed_precision': True,\n",
    "    'epochs': 30,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QdjeHZ3CJlvc"
   },
   "outputs": [],
   "source": [
    "def train(X: pd.DataFrame, y: pd.DataFrame):\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    groups = X['scene']\n",
    "\n",
    "    models = []\n",
    "    oof = np.zeros_like(y)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "        print('=' * 10, f'fold: {fold} start' + '=' * 10)\n",
    "        train_X = X.iloc[train_idx].drop(columns=['scene'])\n",
    "        train_y = y.iloc[train_idx]\n",
    "        valid_X = X.iloc[valid_idx].drop(columns=['scene'])\n",
    "        valid_y = y.iloc[valid_idx]\n",
    "\n",
    "        train_dataset = MLPDataset(train_X, train_y)\n",
    "        val_dataset = MLPDataset(valid_X, valid_y)\n",
    "\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=CONFIG[\"train_batch_size\"],\n",
    "            shuffle=True,\n",
    "            num_workers=CONFIG[\"n_workers\"],\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "        val_dataloader = torch.utils.data.DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=CONFIG[\"valid_batch_size\"],\n",
    "            shuffle=False,\n",
    "            num_workers=CONFIG[\"n_workers\"],\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "\n",
    "        num_warmup_steps = len(train_dataloader)\n",
    "        num_training_steps = len(train_dataloader) * CONFIG[\"epochs\"]\n",
    "\n",
    "        # == init model ==\n",
    "        model = MLPModel(\n",
    "            config=CONFIG,\n",
    "            input_dim=train_X.shape[1],\n",
    "            output_dim=train_y.shape[1],\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps,\n",
    "        )\n",
    "\n",
    "        # == init callback ==\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor=\"valid_loss\",\n",
    "            dirpath=CONFIG[\"output_dir\"],\n",
    "            save_top_k=1,\n",
    "            save_last=False,\n",
    "            save_weights_only=True,\n",
    "            filename=f\"fold_{fold}\",\n",
    "            mode=\"min\",\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"valid_loss\",\n",
    "            min_delta=0.00,\n",
    "            patience=CONFIG[\"patience\"],\n",
    "            verbose=False,\n",
    "            mode=\"min\",\n",
    "        )\n",
    "\n",
    "        callbacks_to_use = [\n",
    "            checkpoint_callback,\n",
    "            early_stopping,\n",
    "            TQDMProgressBar(refresh_rate=1),\n",
    "        ]\n",
    "\n",
    "        # == init trainer ==\n",
    "        trainer = Trainer(\n",
    "            max_epochs=CONFIG[\"epochs\"],\n",
    "            val_check_interval=0.5,\n",
    "            callbacks=callbacks_to_use,\n",
    "            enable_model_summary=False,\n",
    "            accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "            deterministic=True,\n",
    "            precision=\"16-mixed\" if CONFIG[\"mixed_precision\"] else 32,\n",
    "            # logger=wandb_logger,\n",
    "        )\n",
    "\n",
    "        # == Training ==\n",
    "        trainer.fit(\n",
    "            model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    "        )\n",
    "\n",
    "        # == OOF ==\n",
    "        model.to(CONFIG[\"device\"])\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        gts = []\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            with torch.no_grad():\n",
    "                x, gt = batch\n",
    "                x = x.cuda()\n",
    "                outputs = model(x)\n",
    "            predictions.append(outputs.detach().cpu())\n",
    "            gts.append(gt.detach().cpu())\n",
    "\n",
    "        predictions = torch.cat(predictions, dim=0).cpu().detach()\n",
    "        oof[valid_idx] = predictions.numpy().astype(np.float32)\n",
    "\n",
    "        ckpt = CONFIG[\"output_dir\"] / f\"fold_{fold}.ckpt\"\n",
    "        models.append(ckpt)\n",
    "    return models, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "e26SRbzbJlvd"
   },
   "outputs": [],
   "source": [
    "def predict(X: pd.DataFrame, ckpt_list: list):\n",
    "    preds = []\n",
    "\n",
    "    for ckpt in ckpt_list:\n",
    "        # == init model ==\n",
    "        model = MLPModel(\n",
    "            config=CONFIG,\n",
    "            input_dim=X.shape[1],\n",
    "            output_dim=18,\n",
    "        )\n",
    "\n",
    "        # == load ckpt ==\n",
    "        weights = torch.load(ckpt, map_location=torch.device(CONFIG['device']))['state_dict']\n",
    "        model.load_state_dict(weights)\n",
    "        model.to(CONFIG['device'])\n",
    "        model.eval()\n",
    "\n",
    "        # == create dataset & dataloader ==\n",
    "        test_dataset = TestDataset(X)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=CONFIG['valid_batch_size'],\n",
    "            num_workers=CONFIG[\"n_workers\"],\n",
    "            shuffle=False,\n",
    "            drop_last=False\n",
    "        )\n",
    "        start = time.time()\n",
    "        pred = []\n",
    "        for batch in tqdm(test_loader):\n",
    "            with torch.no_grad():\n",
    "                x = batch\n",
    "                x = x.to(CONFIG[\"device\"])\n",
    "\n",
    "                outputs = model(x)\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                # sigmoid\n",
    "                # outputs = scipy.special.expit(outputs)\n",
    "            pred.append(outputs)\n",
    "\n",
    "        pred = np.concatenate(pred, axis=0)\n",
    "\n",
    "        preds.append(pred)\n",
    "        elapsed_time = time.time() - start\n",
    "        print(f'elapsed time: {elapsed_time:.5f}sec')\n",
    "        gc.collect()\n",
    "\n",
    "    return np.mean(preds, axis=0)\n",
    "\n",
    "def evaluate(y_true: pd.DataFrame, y_pred: pd.DataFrame):\n",
    "    return np.mean(np.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpkMHZ9dJlvd",
    "outputId": "a9983e5c-4903-4839-ab9a-11077ced092e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43371, 72)\n",
      "(1727, 54)\n"
     ]
    }
   ],
   "source": [
    "train_df = preprocess(train_df)\n",
    "\n",
    "origin_test_ids = test_df['ID'].to_pandas()\n",
    "test_df = preprocess(test_df)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVyDkbZjJlvd",
    "outputId": "37cc2192-5b5e-482a-f6cb-13d10917e22b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43371, 53)\n",
      "(1727, 53)\n"
     ]
    }
   ],
   "source": [
    "remove_columns = ['ID']\n",
    "X = train_df.drop(remove_columns + TARGET_COLS).to_pandas().fillna(-1)\n",
    "y = train_df[TARGET_COLS].to_pandas()\n",
    "\n",
    "test_X = test_df.drop(remove_columns).to_pandas().fillna(-1)\n",
    "\n",
    "oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X[CAT_COLS] = oe.fit_transform(X[CAT_COLS])\n",
    "test_X[CAT_COLS] = oe.transform(test_X[CAT_COLS])\n",
    "\n",
    "print(X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1n18M8adJlvd"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "num_cols = X.columns[~X.columns.isin(CAT_COLS)]\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "test_X[num_cols] = scaler.transform(test_X[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rQny1P5CjdDl"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "if CONFIG['output_dir'].exists():\n",
    "    shutil.rmtree(CONFIG['output_dir'])\n",
    "    CONFIG['output_dir'].mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191,
     "referenced_widgets": [
      "6a81764956eb4cba86dcc34d06768027",
      "e6c552ac21bc418ba35c2ae739fb8cc3",
      "980b2914a2aa45d093497f82dc482d80",
      "f86ecf5c47274300984726bf53e7ba88",
      "b3eedb78a5c2421a9f44181f9cadf99f",
      "9a80d115284e450192543a8644f609e6",
      "ebc22c97f6f14f1da1b94ef1268948c9",
      "cd664d9a0bc340cbaa01ec6b91801c44",
      "85cb27e228d3489791a0245c8bad1a9e",
      "89568368b94a48a29d0270bf07a60c35",
      "77067e251444499e9b5413e209715c51"
     ]
    },
    "id": "ot2w0BcjJlvd",
    "outputId": "e8617573-43c3-477e-b50f-1ac4c40fbd85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== fold: 0 start==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a81764956eb4cba86dcc34d06768027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "models_dict = {}\n",
    "oof = pd.DataFrame(np.zeros_like(train_df.to_pandas().loc[:, TARGET_COLS]), columns=TARGET_COLS)\n",
    "\n",
    "preds = test_df.select(['ID']).to_pandas()\n",
    "preds[TARGET_COLS] = 0.0\n",
    "\n",
    "ckpt_list, partial_oofs = train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmDTEH8OJlvd"
   },
   "outputs": [],
   "source": [
    "oof.loc[:, :] = partial_oofs\n",
    "preds.loc[:, TARGET_COLS] = predict(test_X.drop(columns=['scene']), ckpt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6339HP2iJlvd"
   },
   "outputs": [],
   "source": [
    "for target in TARGET_COLS:\n",
    "    print(f'{target} CV score: ', evaluate(y[target], oof[target]))\n",
    "score = evaluate(y, oof)\n",
    "print('Total CV score: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0inRFnScJlve"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(origin_test_ids).merge(preds, on='ID', how='left').drop(columns=['ID'])\n",
    "\n",
    "output_path = OUTPUT_DIR / f'{exp_name}_{score:.4f}_submission.csv'\n",
    "if output_path.exists():\n",
    "    assert False, f'output file already exists. {output_path}'\n",
    "\n",
    "submission.to_csv(output_path, index=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "6a81764956eb4cba86dcc34d06768027": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e6c552ac21bc418ba35c2ae739fb8cc3",
       "IPY_MODEL_980b2914a2aa45d093497f82dc482d80",
       "IPY_MODEL_f86ecf5c47274300984726bf53e7ba88"
      ],
      "layout": "IPY_MODEL_b3eedb78a5c2421a9f44181f9cadf99f"
     }
    },
    "77067e251444499e9b5413e209715c51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85cb27e228d3489791a0245c8bad1a9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "89568368b94a48a29d0270bf07a60c35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "980b2914a2aa45d093497f82dc482d80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd664d9a0bc340cbaa01ec6b91801c44",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_85cb27e228d3489791a0245c8bad1a9e",
      "value": 0
     }
    },
    "9a80d115284e450192543a8644f609e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3eedb78a5c2421a9f44181f9cadf99f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "cd664d9a0bc340cbaa01ec6b91801c44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6c552ac21bc418ba35c2ae739fb8cc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a80d115284e450192543a8644f609e6",
      "placeholder": "​",
      "style": "IPY_MODEL_ebc22c97f6f14f1da1b94ef1268948c9",
      "value": "Sanity Checking DataLoader 0:   0%"
     }
    },
    "ebc22c97f6f14f1da1b94ef1268948c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f86ecf5c47274300984726bf53e7ba88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89568368b94a48a29d0270bf07a60c35",
      "placeholder": "​",
      "style": "IPY_MODEL_77067e251444499e9b5413e209715c51",
      "value": " 0/2 [00:00&lt;?, ?it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
